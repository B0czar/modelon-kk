{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff0286e2",
   "metadata": {},
   "source": [
    "# Predição de Sucesso de Startups com Random Forest\n",
    "\n",
    "Notebook inicial focado em gerar rapidamente um modelo baseline e variações de Random Forest para submissão.\n",
    "\n",
    "Serão testadas 4 abordagens:\n",
    "1. Baseline (RandomForest padrão)\n",
    "2. Tuning manual simples (hiperparâmetros escolhidos por heurística)\n",
    "3. RandomizedSearchCV (tuning sem grid exaustivo)\n",
    "4. GridSearchCV (tuning com grid menor focado)\n",
    "\n",
    "Critério de escolha: maior acurácia média em cross-validation (StratifiedKFold). Em caso de empate, escolhe-se o modelo com menor desvio padrão; se ainda empatar, o mais simples.\n",
    "\n",
    "Tarefas mais extensas (EDA aprofundada, engenharia de features avançada, análise de hipóteses detalhada) serão adicionadas depois conforme as regras do README. Aqui priorizamos gerar uma primeira \"submission\" consistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5343a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports principais (apenas libs permitidas: numpy, pandas, scikit-learn, matplotlib, seaborn)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4771eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões train: (646, 33)\n",
      "Dimensões test : (277, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age_first_funding_year</th>\n",
       "      <th>age_last_funding_year</th>\n",
       "      <th>age_first_milestone_year</th>\n",
       "      <th>age_last_milestone_year</th>\n",
       "      <th>relationships</th>\n",
       "      <th>funding_rounds</th>\n",
       "      <th>funding_total_usd</th>\n",
       "      <th>milestones</th>\n",
       "      <th>is_CA</th>\n",
       "      <th>is_NY</th>\n",
       "      <th>is_MA</th>\n",
       "      <th>is_TX</th>\n",
       "      <th>is_otherstate</th>\n",
       "      <th>category_code</th>\n",
       "      <th>is_software</th>\n",
       "      <th>is_web</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_enterprise</th>\n",
       "      <th>is_advertising</th>\n",
       "      <th>is_gamesvideo</th>\n",
       "      <th>is_ecommerce</th>\n",
       "      <th>is_biotech</th>\n",
       "      <th>is_consulting</th>\n",
       "      <th>is_othercategory</th>\n",
       "      <th>has_VC</th>\n",
       "      <th>has_angel</th>\n",
       "      <th>has_roundA</th>\n",
       "      <th>has_roundB</th>\n",
       "      <th>has_roundC</th>\n",
       "      <th>has_roundD</th>\n",
       "      <th>avg_participants</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>719</td>\n",
       "      <td>10.42</td>\n",
       "      <td>13.09</td>\n",
       "      <td>8.98</td>\n",
       "      <td>12.72</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4087500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>45000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>advertising</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.28</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5200000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>photo_video</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.62</td>\n",
       "      <td>10.39</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>14500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>advertising</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>444</td>\n",
       "      <td>0.66</td>\n",
       "      <td>5.88</td>\n",
       "      <td>6.21</td>\n",
       "      <td>8.61</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>70000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>web</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  age_first_funding_year  age_last_funding_year  \\\n",
       "0  719                   10.42                  13.09   \n",
       "1  429                    3.79                   3.79   \n",
       "2  178                    0.71                   2.28   \n",
       "3  197                    3.00                   5.00   \n",
       "4  444                    0.66                   5.88   \n",
       "\n",
       "   age_first_milestone_year  age_last_milestone_year  relationships  \\\n",
       "0                      8.98                    12.72              4   \n",
       "1                       NaN                      NaN             21   \n",
       "2                      1.95                     2.28              5   \n",
       "3                      9.62                    10.39             16   \n",
       "4                      6.21                     8.61             29   \n",
       "\n",
       "   funding_rounds  funding_total_usd  milestones  is_CA  is_NY  is_MA  is_TX  \\\n",
       "0               3            4087500           3      1      0      0      0   \n",
       "1               1           45000000           0      0      1      0      0   \n",
       "2               2            5200000           2      1      0      0      0   \n",
       "3               2           14500000           2      0      0      1      0   \n",
       "4               5           70000000           4      1      0      0      0   \n",
       "\n",
       "   is_otherstate category_code  is_software  is_web  is_mobile  is_enterprise  \\\n",
       "0              0    enterprise            0       0          0              1   \n",
       "1              0   advertising            0       0          0              0   \n",
       "2              0   photo_video            0       0          0              0   \n",
       "3              0   advertising            0       0          0              0   \n",
       "4              0           web            0       1          0              0   \n",
       "\n",
       "   is_advertising  is_gamesvideo  is_ecommerce  is_biotech  is_consulting  \\\n",
       "0               0              0             0           0              0   \n",
       "1               1              0             0           0              0   \n",
       "2               0              0             0           0              0   \n",
       "3               1              0             0           0              0   \n",
       "4               0              0             0           0              0   \n",
       "\n",
       "   is_othercategory  has_VC  has_angel  has_roundA  has_roundB  has_roundC  \\\n",
       "0                 0       1          1           0           0           0   \n",
       "1                 0       0          0           0           1           0   \n",
       "2                 1       1          0           1           0           0   \n",
       "3                 0       0          1           0           1           0   \n",
       "4                 0       0          0           1           1           1   \n",
       "\n",
       "   has_roundD  avg_participants  labels  \n",
       "0           0               1.0       0  \n",
       "1           0               1.0       1  \n",
       "2           0               1.0       0  \n",
       "3           0               2.0       1  \n",
       "4           1               2.8       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregamento dos dados\n",
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'\n",
    "sample_sub_path = 'data/sample_submission.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "sample_sub = pd.read_csv(sample_sub_path)\n",
    "\n",
    "print('Dimensões train:', df_train.shape)\n",
    "print('Dimensões test :', df_test.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeca7c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_first_milestone_year    0.213622\n",
       "age_last_milestone_year     0.171827\n",
       "age_first_funding_year      0.054180\n",
       "age_last_funding_year       0.013932\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checagem rápida de valores ausentes (resumido)\n",
    "missing = df_train.isna().mean().sort_values(ascending=False)\n",
    "missing[missing>0].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9523eed",
   "metadata": {},
   "source": [
    "## Pré-processamento\n",
    "- 'category_code' será one-hot encoded (handle_unknown='ignore').\n",
    "- Colunas numéricas: imputação por mediana.\n",
    "- RandomForest não exige escala, então não aplicamos StandardScaler agora.\n",
    "- Mantemos dummies já existentes como numéricas.\n",
    "- 'id' será removido das features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0006f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir colunas\n",
    "target_col = 'labels'\n",
    "id_col = 'id'\n",
    "categorical_cols = ['category_code']  # apenas esta categórica 'bruta'\n",
    "# Numéricas: todas as numéricas exceto id e target\n",
    "numeric_cols = [c for c in df_train.columns if c not in [target_col, id_col] and c not in categorical_cols]\n",
    "# (Isto inclui as dummies e variáveis contínuas)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='median'), numeric_cols),\n",
    "        ('cat', Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                           ('onehot', OneHotEncoder(handle_unknown='ignore'))]), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def build_pipeline(rf_model: RandomForestClassifier) -> Pipeline:\n",
    "    return Pipeline(steps=[('prep', preprocessor), ('clf', rf_model)])\n",
    "\n",
    "X = df_train.drop(columns=[target_col])\n",
    "y = df_train[target_col]\n",
    "X_test_final = df_test.copy()  # para depois gerar submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c005a4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição treino: {1: 0.647, 0: 0.353}\n",
      "Distribuição validação: {1: 0.646, 0: 0.354}\n"
     ]
    }
   ],
   "source": [
    "# Split para avaliação adicional (além do cross-validation)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n",
    "print('Distribuição treino:', y_tr.value_counts(normalize=True).round(3).to_dict())\n",
    "print('Distribuição validação:', y_val.value_counts(normalize=True).round(3).to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774bab94",
   "metadata": {},
   "source": [
    "## Funções de Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d9d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline(pipeline: Pipeline, X_train, y_train, X_valid, y_valid, cv_splits=5, name='model'):\n",
    "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, preds)\n",
    "    report = classification_report(y_valid, preds, output_dict=True)\n",
    "    cm = confusion_matrix(y_valid, preds)\n",
    "    return {\n",
    "        'name': name,\n",
    "        'cv_mean_acc': cv_scores.mean(),\n",
    "        'cv_std_acc': cv_scores.std(),\n",
    "        'val_acc': acc,\n",
    "        'val_precision_1': report['1']['precision'],\n",
    "        'val_recall_1': report['1']['recall'],\n",
    "        'val_f1_1': report['1']['f1-score'],\n",
    "        'confusion_matrix': cm,\n",
    "        'fitted_pipeline': pipeline\n",
    "    }\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc058a0",
   "metadata": {},
   "source": [
    "## 1. Baseline RandomForest (parâmetros padrão)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0048e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.800429424943988), 0.7846153846153846)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_baseline = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "pipe_baseline = build_pipeline(rf_baseline)\n",
    "res_baseline = evaluate_pipeline(pipe_baseline, X_tr, y_tr, X_val, y_val, name='Baseline')\n",
    "results.append(res_baseline)\n",
    "res_baseline['cv_mean_acc'], res_baseline['val_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ca88c",
   "metadata": {},
   "source": [
    "## 2. Tuning Manual (heurístico)\n",
    "Escolhas: aumentar n_estimators, limitar profundidade moderada, ajustar min_samples_split/leaf e max_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ec4b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7849141150112025), 0.7692307692307693)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_manual = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "pipe_manual = build_pipeline(rf_manual)\n",
    "res_manual = evaluate_pipeline(pipe_manual, X_tr, y_tr, X_val, y_val, name='Manual Tuning')\n",
    "results.append(res_manual)\n",
    "res_manual['cv_mean_acc'], res_manual['val_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39be886",
   "metadata": {},
   "source": [
    "## 3. RandomizedSearchCV (tuning sem grid exaustivo)\n",
    "Exploramos um espaço mais amplo com amostragem aleatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee70f91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'clf__n_estimators': 400,\n",
       "  'clf__min_samples_split': 10,\n",
       "  'clf__min_samples_leaf': 1,\n",
       "  'clf__max_features': 'log2',\n",
       "  'clf__max_depth': 12,\n",
       "  'clf__bootstrap': False},\n",
       " 0.7692307692307693)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'clf__n_estimators': [200, 300, 400, 500, 600, 800],\n",
    "    'clf__max_depth': [None, 5, 8, 10, 12, 15, 20],\n",
    "    'clf__min_samples_split': [2, 5, 10, 15],\n",
    "    'clf__min_samples_leaf': [1, 2, 4, 6],\n",
    "    'clf__max_features': ['sqrt', 'log2', 0.6, 0.8, None],\n",
    "    'clf__bootstrap': [True, False]\n",
    "}\n",
    "base_rf = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "pipe_rand = build_pipeline(base_rf)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=pipe_rand,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=40,\n",
    "    scoring='accuracy',\n",
    "    cv=cv,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "rand_search.fit(X_tr, y_tr)\n",
    "best_rand = rand_search.best_estimator_\n",
    "# Avaliar no holdout\n",
    "preds_val = best_rand.predict(X_val)\n",
    "acc_val = accuracy_score(y_val, preds_val)\n",
    "report = classification_report(y_val, preds_val, output_dict=True)\n",
    "cm = confusion_matrix(y_val, preds_val)\n",
    "res_rand = {\n",
    "    'name': 'RandomizedSearch',\n",
    "    'cv_mean_acc': rand_search.best_score_,\n",
    "    'cv_std_acc': np.nan,  # (sklearn não expõe std direto do melhor conjunto)\n",
    "    'val_acc': acc_val,\n",
    "    'val_precision_1': report['1']['precision'],\n",
    "    'val_recall_1': report['1']['recall'],\n",
    "    'val_f1_1': report['1']['f1-score'],\n",
    "    'confusion_matrix': cm,\n",
    "    'fitted_pipeline': best_rand\n",
    "}\n",
    "results.append(res_rand)\n",
    "rand_search.best_params_, acc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6bd1e",
   "metadata": {},
   "source": [
    "## 4. GridSearchCV (tuning com grid focado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df2fc91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'clf__max_depth': 10,\n",
       "  'clf__max_features': 'log2',\n",
       "  'clf__min_samples_leaf': 1,\n",
       "  'clf__min_samples_split': 2,\n",
       "  'clf__n_estimators': 500},\n",
       " 0.7615384615384615)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'clf__n_estimators': [300, 400, 500],\n",
    "    'clf__max_depth': [None, 10, 15],\n",
    "    'clf__min_samples_split': [2, 5],\n",
    "    'clf__min_samples_leaf': [1, 2],\n",
    "    'clf__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "base_rf2 = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "pipe_grid = build_pipeline(base_rf2)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipe_grid,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_tr, y_tr)\n",
    "best_grid = grid_search.best_estimator_\n",
    "preds_val = best_grid.predict(X_val)\n",
    "acc_val = accuracy_score(y_val, preds_val)\n",
    "report = classification_report(y_val, preds_val, output_dict=True)\n",
    "cm = confusion_matrix(y_val, preds_val)\n",
    "res_grid = {\n",
    "    'name': 'GridSearch',\n",
    "    'cv_mean_acc': grid_search.best_score_,\n",
    "    'cv_std_acc': np.nan,\n",
    "    'val_acc': acc_val,\n",
    "    'val_precision_1': report['1']['precision'],\n",
    "    'val_recall_1': report['1']['recall'],\n",
    "    'val_f1_1': report['1']['f1-score'],\n",
    "    'confusion_matrix': cm,\n",
    "    'fitted_pipeline': best_grid\n",
    "}\n",
    "results.append(res_grid)\n",
    "grid_search.best_params_, acc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b7d55b",
   "metadata": {},
   "source": [
    "## Comparação dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae34532e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>cv_mean_acc</th>\n",
       "      <th>cv_std_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_precision_1</th>\n",
       "      <th>val_recall_1</th>\n",
       "      <th>val_f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomizedSearch</td>\n",
       "      <td>0.802390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.800429</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.840909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GridSearch</td>\n",
       "      <td>0.798525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.828729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manual Tuning</td>\n",
       "      <td>0.784914</td>\n",
       "      <td>0.042985</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.831461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  cv_mean_acc  cv_std_acc   val_acc  val_precision_1  \\\n",
       "2  RandomizedSearch     0.802390         NaN  0.769231         0.781250   \n",
       "0          Baseline     0.800429    0.039836  0.784615         0.804348   \n",
       "3        GridSearch     0.798525         NaN  0.761538         0.773196   \n",
       "1     Manual Tuning     0.784914    0.042985  0.769231         0.787234   \n",
       "\n",
       "   val_recall_1  val_f1_1  \n",
       "2      0.892857  0.833333  \n",
       "0      0.880952  0.840909  \n",
       "3      0.892857  0.828729  \n",
       "1      0.880952  0.831461  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame([{k:v for k,v in r.items() if k not in ['fitted_pipeline','confusion_matrix']} for r in results])\n",
    "results_df.sort_values(by='cv_mean_acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "906e0df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo: RandomizedSearch  - CV Acc: 0.8023898431665423  - Val Acc: 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "# Selecionar melhor modelo conforme regra (maior cv_mean_acc, depois menor std, depois preferência por simplicidade)\n",
    "sorted_res = sorted(results, key=lambda r: (r['cv_mean_acc'], - (0 if np.isnan(r['cv_std_acc']) else r['cv_std_acc'])), reverse=True)\n",
    "best = sorted_res[0]\n",
    "print('Melhor modelo:', best['name'], ' - CV Acc:', best['cv_mean_acc'], ' - Val Acc:', best['val_acc'])\n",
    "best_pipeline = best['fitted_pipeline']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb249efa",
   "metadata": {},
   "source": [
    "## Treino Final em TODO o Conjunto de Treino e Geração da Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae1e2aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  labels\n",
       "0   70       1\n",
       "1   23       0\n",
       "2  389       1\n",
       "3  872       1\n",
       "4  920       1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit no dataset completo de treino (X, y) para aproveitar todos os exemplos\n",
    "# (Se o best já for resultado de search, re-fit para garantir uso de todos os dados)\n",
    "best_params_model = best_pipeline\n",
    "best_params_model.fit(X, y)\n",
    "test_preds = best_params_model.predict(X_test_final)\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test_final[id_col],\n",
    "    'labels': test_preds.astype(int)\n",
    "})\n",
    "submission_path = 'submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56675a8a",
   "metadata": {},
   "source": [
    "### Observações Próximos Passos\n",
    "- Adicionar análise exploratória (distribuições, correlações, hipóteses).\n",
    "- Verificar importância de features (`feature_importances_`) e eventualmente reduzir dimensionalidade.\n",
    "- Avaliar impacto de class_weight='balanced'.\n",
    "- Testar threshold tuning e outras métricas (F1, ROC AUC).\n",
    "- Documentar formalmente 3 hipóteses e validar.\n",
    "\n",
    "Este notebook entrega rapidamente um pipeline funcional e uma submissão inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cec658",
   "metadata": {},
   "source": [
    "## Melhoria: Engenharia de Features e Flags de Missing\n",
    "Vamos criar novas features simples para tentar ultrapassar 0.80 de acurácia:\n",
    "\n",
    "Novas Features:\n",
    "- funding_per_round = funding_total_usd / (funding_rounds + 1)\n",
    "- relationships_per_round = relationships / (funding_rounds + 1)\n",
    "- age_funding_span = age_last_funding_year - age_first_funding_year\n",
    "- milestone_per_round = milestones / (funding_rounds + 1)\n",
    "- funding_rounds_squared (não-linearidade)\n",
    "- log_funding_total_usd = log1p(funding_total_usd)\n",
    "- avg_participants_squared (curvatura)\n",
    "\n",
    "Flags de Missing (0/1): age_first_funding_year, age_last_funding_year, age_first_milestone_year, age_last_milestone_year, funding_total_usd.\n",
    "\n",
    "Depois criamos novo pipeline e repetimos tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f2598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de novas features (train e test devem receber transformações consistentes)\n",
    "\n",
    "def add_engineered_features(df: pd.DataFrame, is_train=True):\n",
    "    d = df.copy()\n",
    "    # Avoid division by zero adding +1\n",
    "    d['funding_per_round'] = d['funding_total_usd'] / (d['funding_rounds'] + 1)\n",
    "    d['relationships_per_round'] = d['relationships'] / (d['funding_rounds'] + 1)\n",
    "    d['age_funding_span'] = d['age_last_funding_year'] - d['age_first_funding_year']\n",
    "    d['milestone_per_round'] = d['milestones'] / (d['funding_rounds'] + 1)\n",
    "    d['funding_rounds_squared'] = d['funding_rounds'] ** 2\n",
    "    d['avg_participants_squared'] = d['avg_participants'] ** 2\n",
    "    d['log_funding_total_usd'] = np.log1p(d['funding_total_usd'])\n",
    "\n",
    "    # Flags de missing\n",
    "    miss_cols = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year',\n",
    "                 'age_last_milestone_year','funding_total_usd']\n",
    "    for c in miss_cols:\n",
    "        d[f'flag_missing_{c}'] = d[c].isna().astype(int)\n",
    "    return d\n",
    "\n",
    "X_eng = add_engineered_features(X)\n",
    "X_tr_eng = add_engineered_features(X_tr)\n",
    "X_val_eng = add_engineered_features(X_val)\n",
    "X_test_eng = add_engineered_features(X_test_final)\n",
    "\n",
    "# Atualizar listas de colunas\n",
    "categorical_cols_eng = ['category_code']\n",
    "# Numeric columns = everything except id, category_code, target (target já fora) e manter consistência\n",
    "numeric_cols_eng = [c for c in X_eng.columns if c not in [id_col] + categorical_cols_eng]\n",
    "\n",
    "preprocessor_eng = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='median'), numeric_cols_eng),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_cols_eng)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def build_pipeline_eng(rf_model: RandomForestClassifier) -> Pipeline:\n",
    "    return Pipeline(steps=[('prep', preprocessor_eng), ('clf', rf_model)])\n",
    "\n",
    "print('Novas colunas criadas:', set(X_eng.columns) - set(X.columns))\n",
    "print('Total de features antes:', len(X.columns)-1, ' | depois:', len(X_eng.columns)-1)  # -1 exclui id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c99857",
   "metadata": {},
   "source": [
    "## Tuning Avançado com Espaço Expandido (RandomizedSearch)\n",
    "Incluímos agora hiperparâmetros adicionais:\n",
    "- class_weight (para lidar com leve desbalanceamento)\n",
    "- max_samples (subamostragem para aumentar diversidade de árvores)\n",
    "E aumentamos n_iter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "cv_eng = StratifiedKFold(n_splits=6, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "rf_base_eng = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "pipe_eng = build_pipeline_eng(rf_base_eng)\n",
    "\n",
    "param_dist_eng = {\n",
    "    'clf__n_estimators': randint(400, 1200),\n",
    "    'clf__max_depth': [None] + list(range(8, 26, 2)),\n",
    "    'clf__min_samples_split': randint(2, 15),\n",
    "    'clf__min_samples_leaf': randint(1, 8),\n",
    "    'clf__max_features': ['sqrt', 'log2', 0.5, 0.7, None],\n",
    "    'clf__bootstrap': [True, False],\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "    'clf__max_samples': [None, 0.7, 0.85, 0.9]\n",
    "}\n",
    "\n",
    "rand_search_eng = RandomizedSearchCV(\n",
    "    estimator=pipe_eng,\n",
    "    param_distributions=param_dist_eng,\n",
    "    n_iter=80,\n",
    "    scoring='accuracy',\n",
    "    cv=cv_eng,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rand_search_eng.fit(X_tr_eng, y_tr)\n",
    "\n",
    "best_eng = rand_search_eng.best_estimator_\n",
    "val_preds_eng = best_eng.predict(X_val_eng)\n",
    "acc_val_eng = accuracy_score(y_val, val_preds_eng)\n",
    "print('Melhor params (eng):', rand_search_eng.best_params_)\n",
    "print('CV best score:', rand_search_eng.best_score_)\n",
    "print('Val acc:', acc_val_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0dfdd",
   "metadata": {},
   "source": [
    "## Ensemble (Stacking Simples por Média de Probabilidades)\n",
    "Combinamos o melhor modelo anterior e o novo modelo melhorado (se o novo superar 0.80) via média de probabilidades para potencialmente ganhar alguns décimos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea53e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar ensemble: usar best_pipeline (antigo) e best_eng (novo com features)\n",
    "\n",
    "# Garantir que ambos estejam treinados em seus respectivos espaços completos de treino antes de ensemble final\n",
    "# Refit best antigo em X (sem engineered) + y\n",
    "best_pipeline.fit(X, y)\n",
    "# Refit best_eng em X_eng + y\n",
    "best_eng.fit(X_eng, y)\n",
    "\n",
    "# Avaliação ensemble no holdout de validação\n",
    "proba_old = best_pipeline.predict_proba(X_val)[:,1]\n",
    "proba_new = best_eng.predict_proba(X_val_eng)[:,1]\n",
    "proba_avg = (proba_old + proba_new)/2\n",
    "preds_ensemble = (proba_avg >= 0.5).astype(int)\n",
    "acc_ensemble = accuracy_score(y_val, preds_ensemble)\n",
    "print('Acurácia ensemble (val):', acc_ensemble)\n",
    "\n",
    "# Escolha final\n",
    "candidates = [\n",
    "    ('old_best', best_pipeline, accuracy_score(y_val, best_pipeline.predict(X_val))),\n",
    "    ('new_best', best_eng, accuracy_score(y_val, best_eng.predict(X_val_eng))),\n",
    "    ('ensemble_avg', ('ensemble', best_pipeline, best_eng), acc_ensemble)\n",
    "]\n",
    "\n",
    "for name, model_obj, acc in candidates:\n",
    "    print(f\"{name}: val_acc={acc:.5f}\")\n",
    "\n",
    "selected_name, selected_model, selected_acc = max(candidates, key=lambda x: x[2])\n",
    "print('\\nSelecionado para submissão:', selected_name, ' - Val Acc:', selected_acc)\n",
    "\n",
    "# Treino final no conjunto completo\n",
    "if selected_name == 'old_best':\n",
    "    final_model = best_pipeline.fit(X, y)\n",
    "    test_proba = final_model.predict_proba(X_test_final)[:,1]\n",
    "    test_preds_final = (test_proba >= 0.5).astype(int)\n",
    "elif selected_name == 'new_best':\n",
    "    final_model = best_eng.fit(X_eng, y)\n",
    "    test_proba = final_model.predict_proba(X_test_eng)[:,1]\n",
    "    test_preds_final = (test_proba >= 0.5).astype(int)\n",
    "else:\n",
    "    # ensemble\n",
    "    best_pipeline.fit(X, y)\n",
    "    best_eng.fit(X_eng, y)\n",
    "    proba_old_test = best_pipeline.predict_proba(X_test_final)[:,1]\n",
    "    proba_new_test = best_eng.predict_proba(X_test_eng)[:,1]\n",
    "    test_proba = (proba_old_test + proba_new_test)/2\n",
    "    test_preds_final = (test_proba >= 0.5).astype(int)\n",
    "\n",
    "submission2 = pd.DataFrame({'id': X_test_final[id_col], 'labels': test_preds_final})\n",
    "submission2.to_csv('submission_v2.csv', index=False)\n",
    "print('Gerado submission_v2.csv')\n",
    "submission2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210fbd88",
   "metadata": {},
   "source": [
    "## Ajuste de Threshold (Opcional)\n",
    "Podemos verificar se mover o limiar de 0.5 melhora a acurácia (dado leve desbalanceamento). Avaliamos thresholds de 0.4 a 0.6.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe1b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold tuning baseado no modelo selecionado (se ensemble, usa média)\n",
    "import numpy as np\n",
    "\n",
    "# Garantir que test_proba está disponível (gerada anteriormente). Se não, recalculamos para selected_name.\n",
    "if 'test_proba' not in globals():\n",
    "    # Recalcular proba de validação para threshold search\n",
    "    if selected_name == 'old_best':\n",
    "        proba_val_ref = best_pipeline.predict_proba(X_val)[:,1]\n",
    "    elif selected_name == 'new_best':\n",
    "        proba_val_ref = best_eng.predict_proba(X_val_eng)[:,1]\n",
    "    else:\n",
    "        proba_old_tmp = best_pipeline.predict_proba(X_val)[:,1]\n",
    "        proba_new_tmp = best_eng.predict_proba(X_val_eng)[:,1]\n",
    "        proba_val_ref = (proba_old_tmp + proba_new_tmp)/2\n",
    "else:\n",
    "    # Precisamos da proba de validação\n",
    "    if selected_name == 'old_best':\n",
    "        proba_val_ref = best_pipeline.predict_proba(X_val)[:,1]\n",
    "    elif selected_name == 'new_best':\n",
    "        proba_val_ref = best_eng.predict_proba(X_val_eng)[:,1]\n",
    "    else:\n",
    "        proba_old_tmp = best_pipeline.predict_proba(X_val)[:,1]\n",
    "        proba_new_tmp = best_eng.predict_proba(X_val_eng)[:,1]\n",
    "        proba_val_ref = (proba_old_tmp + proba_new_tmp)/2\n",
    "\n",
    "thresholds = np.linspace(0.4, 0.6, 21)\n",
    "accs = []\n",
    "for t in thresholds:\n",
    "    preds_t = (proba_val_ref >= t).astype(int)\n",
    "    accs.append(accuracy_score(y_val, preds_t))\n",
    "\n",
    "best_t_idx = int(np.argmax(accs))\n",
    "best_threshold = thresholds[best_t_idx]\n",
    "print('Melhor threshold em validação:', best_threshold, ' - acc:', accs[best_t_idx])\n",
    "\n",
    "# Se o threshold melhor for diferente de 0.5, refazer submissão final com esse threshold\n",
    "if abs(best_threshold - 0.5) > 1e-6:\n",
    "    if selected_name == 'old_best':\n",
    "        final_model = best_pipeline.fit(X, y)\n",
    "        proba_test_final = final_model.predict_proba(X_test_final)[:,1]\n",
    "    elif selected_name == 'new_best':\n",
    "        final_model = best_eng.fit(X_eng, y)\n",
    "        proba_test_final = final_model.predict_proba(X_test_eng)[:,1]\n",
    "    else:\n",
    "        best_pipeline.fit(X, y)\n",
    "        best_eng.fit(X_eng, y)\n",
    "        po = best_pipeline.predict_proba(X_test_final)[:,1]\n",
    "        pn = best_eng.predict_proba(X_test_eng)[:,1]\n",
    "        proba_test_final = (po + pn)/2\n",
    "    tuned_preds = (proba_test_final >= best_threshold).astype(int)\n",
    "    submission_tuned = pd.DataFrame({'id': X_test_final[id_col], 'labels': tuned_preds})\n",
    "    submission_tuned.to_csv('submission_tuned.csv', index=False)\n",
    "    print('Gerado submission_tuned.csv com threshold ajustado.')\n",
    "else:\n",
    "    print('Threshold 0.5 já é o melhor. Mantida submission anterior.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
